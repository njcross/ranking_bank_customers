{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "249b05b3",
   "metadata": {},
   "source": [
    "# Required Assignment 17.1 — Comparing Classifiers (Bank Marketing)\n",
    "Nicholas Cross\n",
    "\n",
    "**Goal:** Compare k-nearest neighbors (KNN), logistic regression, decision trees, and support vector machines (SVM) to predict whether a client subscribes to a term deposit (`y`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5124c6c6",
   "metadata": {},
   "source": [
    "## 1. Business Problem\n",
    "The bank runs outbound phone campaigns to offer term deposits. Calls have a cost (agent time) and a potential payoff (subscription). We want to **prioritize which clients to call** to maximize conversions and reduce wasted calls.\n",
    "\n",
    "This is a **binary classification** problem. Because the positive class (`y=yes`) is typically rarer, we focus on **F1** and **recall** for the positive class, not accuracy alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1368bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from scipy.stats import chi2_contingency, ttest_ind\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    f1_score, recall_score, precision_score, roc_auc_score, RocCurveDisplay\n",
    ")\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04017678",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "We use the UCI Bank Marketing dataset (`bank-additional-full.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fed63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (robust path handling)\n",
    "candidate_paths = [\n",
    "    Path(\"data/bank-additional-full.csv\"),\n",
    "    Path(\"./data/bank-additional-full.csv\"),\n",
    "    Path(\"../data/bank-additional-full.csv\"),\n",
    "]\n",
    "\n",
    "data_path = None\n",
    "for p in candidate_paths:\n",
    "    if p.exists():\n",
    "        data_path = p\n",
    "        break\n",
    "\n",
    "if data_path is None:\n",
    "    raise FileNotFoundError(\"Could not find bank-additional-full.csv\")\n",
    "\n",
    "df = pd.read_csv(data_path, sep=';')\n",
    "df.shape, df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c840164",
   "metadata": {},
   "source": [
    "## 3. Data Understanding\n",
    "### 3.1 Target distribution (class imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a67fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_counts = df[\"y\"].value_counts()\n",
    "target_pct = df[\"y\"].value_counts(normalize=True) * 100\n",
    "display(pd.DataFrame({\"count\": target_counts, \"percent\": target_pct.round(2)}))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(target_counts.index.astype(str), target_counts.values)\n",
    "plt.title(\"Target Distribution (y)\")\n",
    "plt.xlabel(\"Subscribed to term deposit?\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee30ea33",
   "metadata": {},
   "source": [
    "### 3.2 Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a61bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "numeric_cols, cat_cols[:5], len(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dded3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numeric_cols].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f132d5ea",
   "metadata": {},
   "source": [
    "### 3.3 Key plots\n",
    "**Note on leakage:** `duration` (call length) is known after/during the call. It may be unusable for deciding *who to call*.\n",
    "We will evaluate models both **with** and **without** `duration`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239827c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distribution by outcome\n",
    "plt.figure(figsize=(7,4))\n",
    "for label in [\"no\", \"yes\"]:\n",
    "    subset = df.loc[df[\"y\"] == label, \"age\"]\n",
    "    plt.hist(subset, bins=30, alpha=0.5, density=True, label=label)\n",
    "plt.title(\"Age Distribution by Outcome\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend(title=\"y\")\n",
    "plt.show()\n",
    "\n",
    "# Duration boxplot by outcome\n",
    "plt.figure(figsize=(7,4))\n",
    "df.boxplot(column=\"duration\", by=\"y\")\n",
    "plt.title(\"Call Duration by Outcome\")\n",
    "plt.suptitle(\"\")\n",
    "plt.xlabel(\"Subscribed?\")\n",
    "plt.ylabel(\"Duration (seconds)\")\n",
    "plt.show()\n",
    "\n",
    "# Previous campaign outcome vs subscription\n",
    "ct = pd.crosstab(df[\"poutcome\"], df[\"y\"])\n",
    "ct.plot(kind=\"bar\", figsize=(10,4))\n",
    "plt.title(\"Previous Campaign Outcome vs Subscription\")\n",
    "plt.xlabel(\"poutcome\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend(title=\"y\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37bfc0a",
   "metadata": {},
   "source": [
    "## 4. Inferential statistics (quick checks)\n",
    "- **Chi-square** tests for association between selected categorical variables and `y`\n",
    "- A simple mean comparison (Welch t-test) for `age` across outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb7b7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_to_test = [\"job\", \"marital\", \"education\", \"contact\", \"month\", \"poutcome\"]\n",
    "\n",
    "chi_results = []\n",
    "for c in cat_to_test:\n",
    "    ct = pd.crosstab(df[c], df[\"y\"])\n",
    "    chi2, p, dof, exp = chi2_contingency(ct)\n",
    "    chi_results.append({\"feature\": c, \"chi2\": chi2, \"dof\": dof, \"p_value\": p})\n",
    "\n",
    "pd.DataFrame(chi_results).sort_values(\"p_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43261e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_yes = df.loc[df[\"y\"]==\"yes\", \"age\"]\n",
    "age_no = df.loc[df[\"y\"]==\"no\", \"age\"]\n",
    "t_stat, p_val = ttest_ind(age_yes, age_no, equal_var=False)\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"group\": [\"yes\", \"no\"],\n",
    "    \"mean_age\": [age_yes.mean(), age_no.mean()],\n",
    "    \"std_age\": [age_yes.std(), age_no.std()],\n",
    "    \"n\": [len(age_yes), len(age_no)]\n",
    "})\n",
    "summary, (t_stat, p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40deaff3",
   "metadata": {},
   "source": [
    "## 5. Preprocessing\n",
    "We encode the target as 1/0, one-hot encode categoricals, and scale numerics. We keep a stratified train/test split.\n",
    "\n",
    "We build:\n",
    "1) `X_all` (includes `duration`)\n",
    "2) `X_no_duration` (excludes `duration` for pre-call targeting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d500936",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df.copy()\n",
    "df_model[\"y\"] = (df_model[\"y\"] == \"yes\").astype(int)\n",
    "\n",
    "X_all = df_model.drop(columns=[\"y\"])\n",
    "y = df_model[\"y\"]\n",
    "X_no_duration = X_all.drop(columns=[\"duration\"])\n",
    "\n",
    "X_train_all, X_test_all, y_train, y_test = train_test_split(\n",
    "    X_all, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train_nodur, X_test_nodur, _, _ = train_test_split(\n",
    "    X_no_duration, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "numeric_cols_all = X_all.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
    "cat_cols_all = X_all.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "numeric_cols_nodur = X_no_duration.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
    "cat_cols_nodur = X_no_duration.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "X_train_all.shape, X_train_nodur.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad983859",
   "metadata": {},
   "source": [
    "## 6. Modeling + Evaluation\n",
    "We use **Stratified 5-fold CV** and **GridSearchCV**.\n",
    "Primary selection metric: **F1** for the positive class (`y=1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc2f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def build_preprocessor(numeric_cols, cat_cols):\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), numeric_cols),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "def evaluate_best_model(best_estimator, X_test, y_test, title=\"Model\"):\n",
    "    y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "    y_proba = None\n",
    "    if hasattr(best_estimator, \"predict_proba\"):\n",
    "        y_proba = best_estimator.predict_proba(X_test)[:, 1]\n",
    "    elif hasattr(best_estimator, \"decision_function\"):\n",
    "        scores = best_estimator.decision_function(X_test)\n",
    "        y_proba = (scores - scores.min()) / (scores.max() - scores.min() + 1e-9)\n",
    "\n",
    "    print(f\"=== {title} ===\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    ConfusionMatrixDisplay(cm).plot(values_format=\"d\")\n",
    "    plt.title(f\"Confusion Matrix — {title}\")\n",
    "    plt.show()\n",
    "\n",
    "    if y_proba is not None:\n",
    "        RocCurveDisplay.from_predictions(y_test, y_proba)\n",
    "        plt.title(f\"ROC Curve — {title}\")\n",
    "        plt.show()\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_test, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_test, y_pred, zero_division=0),\n",
    "        \"roc_auc\": roc_auc_score(y_test, y_proba) if y_proba is not None else np.nan\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af12d9",
   "metadata": {},
   "source": [
    "## 7. Train + Tune Models (with `duration`)\n",
    "Upper-bound performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ab7a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_all = build_preprocessor(numeric_cols_all, cat_cols_all)\n",
    "\n",
    "models = {\n",
    "    \"KNN\": (KNeighborsClassifier(), {\n",
    "        \"model__n_neighbors\": [5, 15],\n",
    "        \"model__weights\": [\"uniform\", \"distance\"],\n",
    "    }),\n",
    "    \"LogisticRegression\": (LogisticRegression(max_iter=2000, class_weight=\"balanced\"), {\n",
    "        \"model__C\": [0.5, 1.0, 2.0],\n",
    "    }),\n",
    "    \"DecisionTree\": (DecisionTreeClassifier(class_weight=\"balanced\", random_state=42), {\n",
    "        \"model__max_depth\": [3, 5, None],\n",
    "        \"model__min_samples_split\": [2, 20],\n",
    "        \"model__min_samples_leaf\": [1, 10],\n",
    "    }),\n",
    "    \"SVC_RBF\": (SVC(kernel=\"rbf\", probability=True, class_weight=\"balanced\"), {\n",
    "        \"model__C\": [1.0, 5.0],\n",
    "        \"model__gamma\": [\"scale\", 0.1],\n",
    "    })\n",
    "}\n",
    "\n",
    "results_all = []\n",
    "best_models_all = {}\n",
    "\n",
    "for name, (est, param_grid) in models.items():\n",
    "    pipe = Pipeline(steps=[(\"pre\", pre_all), (\"model\", est)])\n",
    "    gs = GridSearchCV(pipe, param_grid=param_grid, cv=cv, scoring=\"f1\", n_jobs=-1, verbose=0)\n",
    "    gs.fit(X_train_all, y_train)\n",
    "\n",
    "    best_models_all[name] = gs.best_estimator_\n",
    "    results_all.append({\"model\": name, \"best_f1_cv\": gs.best_score_, \"best_params\": gs.best_params_})\n",
    "\n",
    "pd.DataFrame(results_all).sort_values(\"best_f1_cv\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165855dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics_all = []\n",
    "for name, best_est in best_models_all.items():\n",
    "    metrics = evaluate_best_model(best_est, X_test_all, y_test, title=f\"{name} (with duration)\")\n",
    "    metrics[\"model\"] = name\n",
    "    test_metrics_all.append(metrics)\n",
    "\n",
    "pd.DataFrame(test_metrics_all).set_index(\"model\").sort_values(\"f1\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5097e5cc",
   "metadata": {},
   "source": [
    "## 8. Train + Tune Models (without `duration`)\n",
    "More realistic for pre-call targeting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8510b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_nodur = build_preprocessor(numeric_cols_nodur, cat_cols_nodur)\n",
    "\n",
    "results_nodur = []\n",
    "best_models_nodur = {}\n",
    "\n",
    "for name, (est, param_grid) in models.items():\n",
    "    pipe = Pipeline(steps=[(\"pre\", pre_nodur), (\"model\", est)])\n",
    "    gs = GridSearchCV(pipe, param_grid=param_grid, cv=cv, scoring=\"f1\", n_jobs=-1, verbose=0)\n",
    "    gs.fit(X_train_nodur, y_train)\n",
    "\n",
    "    best_models_nodur[name] = gs.best_estimator_\n",
    "    results_nodur.append({\"model\": name, \"best_f1_cv\": gs.best_score_, \"best_params\": gs.best_params_})\n",
    "\n",
    "pd.DataFrame(results_nodur).sort_values(\"best_f1_cv\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eddcebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics_nodur = []\n",
    "for name, best_est in best_models_nodur.items():\n",
    "    metrics = evaluate_best_model(best_est, X_test_nodur, y_test, title=f\"{name} (no duration)\")\n",
    "    metrics[\"model\"] = name\n",
    "    test_metrics_nodur.append(metrics)\n",
    "\n",
    "pd.DataFrame(test_metrics_nodur).set_index(\"model\").sort_values(\"f1\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efacd39",
   "metadata": {},
   "source": [
    "## 9. Interpretability\n",
    "### 9.1 Logistic Regression coefficients (no-duration)\n",
    "We show the largest positive/negative coefficients as a stakeholder-friendly explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52709e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names(preprocessor, numeric_cols, cat_cols):\n",
    "    ohe = preprocessor.named_transformers_[\"cat\"]\n",
    "    cat_feature_names = ohe.get_feature_names_out(cat_cols)\n",
    "    return np.concatenate([np.array(numeric_cols), cat_feature_names])\n",
    "\n",
    "lr_best = best_models_nodur[\"LogisticRegression\"]\n",
    "pre = lr_best.named_steps[\"pre\"]\n",
    "model = lr_best.named_steps[\"model\"]\n",
    "\n",
    "feature_names = get_feature_names(pre, numeric_cols_nodur, cat_cols_nodur)\n",
    "coef_df = pd.DataFrame({\"feature\": feature_names, \"coef\": model.coef_.ravel()})\n",
    "\n",
    "top_pos = coef_df.sort_values(\"coef\", ascending=False).head(15)\n",
    "top_neg = coef_df.sort_values(\"coef\", ascending=True).head(15)\n",
    "\n",
    "top_pos, top_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190ae9bb",
   "metadata": {},
   "source": [
    "### 9.2 Decision Tree feature importances (no-duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511510b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_best = best_models_nodur[\"DecisionTree\"]\n",
    "pre = dt_best.named_steps[\"pre\"]\n",
    "tree = dt_best.named_steps[\"model\"]\n",
    "\n",
    "feature_names = get_feature_names(pre, numeric_cols_nodur, cat_cols_nodur)\n",
    "imp_df = pd.DataFrame({\"feature\": feature_names, \"importance\": tree.feature_importances_}).sort_values(\"importance\", ascending=False)\n",
    "imp_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6fbfe9",
   "metadata": {},
   "source": [
    "## 10. Findings (Actionable Insights)\n",
    "- **Don’t use accuracy alone** due to class imbalance; use **F1/recall**.\n",
    "- `duration` boosts performance but is not usable for *pre-call* decisions.\n",
    "- For *pre-call targeting*, pick the best **no-duration** model to rank customers for calling.\n",
    "- Keep an interpretable model (Logistic Regression or shallow Decision Tree) for explaining drivers.\n",
    "\n",
    "**Recommendation:** Use model scores to build a prioritized call list, then tune the decision threshold based on how many calls the team can place per day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8c217e",
   "metadata": {},
   "source": [
    "## 11. Next Steps\n",
    "- Add cost-sensitive evaluation (profit per call) using business values for TP/FP/FN.\n",
    "- Calibrate probabilities and tune thresholds to match campaign capacity.\n",
    "- Benchmark ensembles (Random Forest / Gradient Boosting) as a follow-up.\n",
    "- Consider a temporal split if campaigns are time-dependent (avoid look-ahead bias)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
